{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "image_path='/home/jason/data/coco/images/'\n",
    "mode='train2014/'\n",
    "image_list=[]\n",
    "image_list.extend(glob.glob(os.path.join(image_path,mode, '*.jpg')))\n",
    "image_list.sort()\n",
    "print(len(image_list))\n",
    "\n",
    "text_path='/home/jason/data/coco/text/'\n",
    "label_list = []\n",
    "label_list.extend(glob.glob(os.path.join(text_path,mode, '*.txt')))\n",
    "label_list.sort()\n",
    "print(len(label_list))\n",
    "\n",
    "with open(label_list[0], \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    label = random.choice(data)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bd3ffa70ab44b9b8805d6955ab1fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: tensor(0.9980, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0322, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9980, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0684, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0762, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0186, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0791, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0576, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0605, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9224, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0293, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8604, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9082, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9775, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.6729, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8730, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9097, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9004, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8286, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9644, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8276, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8311, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9424, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9214, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8169, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7881, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8027, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.6846, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9839, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8301, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0127, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7949, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8115, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7354, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7949, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7485, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7896, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8433, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8428, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7939, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9941, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9238, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7979, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8384, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7886, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7490, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8682, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8506, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8096, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1113, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8535, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9434, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9443, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.7744, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8604, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0020, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0059, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9424, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8955, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9707, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8433, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9746, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9849, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9863, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0498, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.8467, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0068, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9033, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1885, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9634, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1035, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9268, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(0.9370, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0488, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0801, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1035, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1699, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0684, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1055, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.0762, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1211, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1621, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2129, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1934, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1035, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.3779, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1387, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2695, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2627, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2002, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2695, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2207, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1045, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.3379, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2100, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.4512, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.4004, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.3574, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.1699, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7285, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.3887, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6543, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.3730, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.4678, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.4121, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.4160, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7363, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.5527, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6973, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.2988, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.5898, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.5879, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6387, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6387, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.5059, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7305, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7070, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6738, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7822, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.9355, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6816, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7080, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6631, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.8184, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7646, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7598, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6533, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7256, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.8994, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7402, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.9824, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.8613, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.8340, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.8770, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.8086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7080, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7822, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.8828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.9277, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7695, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.9980, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.8701, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.9121, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.7197, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.0742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.9043, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.6611, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.0781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.0098, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.9180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2168, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.9043, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.8965, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.9580, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.0742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(1.9609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.1172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2168, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.0742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.6289, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2363, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.1133, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.1699, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3223, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.1680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.1953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3926, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.1680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.4512, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2305, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2754, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2461, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.4785, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3418, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.4043, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2988, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.5332, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2637, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3301, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.2012, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.9414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.9805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.6152, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.5977, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7988, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7754, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.6191, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.6289, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7461, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7285, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.5879, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7324, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.5527, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.5488, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7148, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7129, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7070, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.9766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3., device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1211, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7520, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.9648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0977, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.6914, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1289, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8711, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.9004, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1582, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0723, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.9414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0898, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.2676, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1211, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0254, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.8613, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.7031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1367, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0820, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364e58366ac444f2848d653c04ef461d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: tensor(2.9453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1543, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.9512, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6973, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7852, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7246, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6367, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.2617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5332, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.2520, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.2539, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.3008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5684, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1699, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.3340, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1992, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1270, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4277, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(2.9883, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.0742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.2539, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6836, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6387, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7441, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.2109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4980, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6211, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5664, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5488, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5293, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5898, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7227, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6426, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9707, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7559, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8301, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8027, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.4941, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6348, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6289, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8691, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8535, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6914, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7148, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5840, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5410, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.5449, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1055, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2148, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7461, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7324, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9473, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9824, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0977, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1289, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0664, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0664, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9316, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1445, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1445, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4., device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9746, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.7500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.8984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(3.9922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4., device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1836, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2227, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1523, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1133, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2539, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1914, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2305, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2227, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4883, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2852, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1445, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72131e7e228943609dcacbbd07d916e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2852, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.8945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.8516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5977, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6367, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.8750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5977, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5898, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6367, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5820, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7539, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6836, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6211, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.8828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(5.0547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.8516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7852, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6523, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4883, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5898, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7227, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.8086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.8203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6523, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3711, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6602, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5977, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6836, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5977, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6133, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6055, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3de0ffd8e04d6a8df0be322e4dd197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6445, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5898, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5664, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6445, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6133, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6055, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6914, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5820, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5820, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6055, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6445, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.8438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.9062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.8398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5664, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5820, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6211, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6523, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6211, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6289, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6055, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6914, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6133, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6055, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017555424ba24fb095ff9e0b49d1bd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5898, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6445, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7148, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5977, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4883, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5664, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6602, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3711, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6914, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7070, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6289, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4883, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4883, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5898, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6211, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6523, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2227, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6250, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5820, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5664, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5820, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5664, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3711, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.7266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6055, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58e55d500144e7b87733e781e0409bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4883, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6367, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6523, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2695, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5664, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2852, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4883, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2461, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5742, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6211, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307c10c3e7814f6591e6621e70a455c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6211, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3711, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3711, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5039, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3711, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2695, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3711, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5664, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5703, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f28e7597d64bc986b92f28d156d191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2539, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2227, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2695, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2695, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2305, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5312, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2070, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2227, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2461, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6016, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5625, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2852, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2461, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2227, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2539, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1562, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d21bba938414f84a94f41b2c7a19aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2461, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3711, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2148, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1992, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2852, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5859, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5586, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2539, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2148, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5547, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5977, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5391, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4727, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6406, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2148, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5078, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.6172, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3711, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2852, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4805, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0938, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5273, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5234, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2461, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1992, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1914, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4570, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2109, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2695, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1367, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "epoch: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2da37e4d60c4edebfe87620c10dcc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5508, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1758, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2070, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2305, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4961, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5430, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2617, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4414, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0977, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1992, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2539, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1328, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5898, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2461, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2852, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1484, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.0781, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4258, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5352, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2188, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2852, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4922, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1680, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2031, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5156, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4023, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3398, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4375, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1875, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4531, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4453, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4219, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4102, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2773, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5000, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4688, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4609, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3477, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3867, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1953, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3164, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1641, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2344, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5195, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2266, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2539, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3125, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3828, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4492, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3633, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3086, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3555, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3594, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3750, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3438, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4648, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2383, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3672, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3789, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4297, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3906, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3984, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4844, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2500, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4180, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2578, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4766, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3945, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5117, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4336, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2812, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3516, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2891, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.5469, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3242, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4141, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1797, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3320, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2930, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2656, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3281, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1719, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3008, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2734, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3203, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3359, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2969, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.2422, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.4062, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.3047, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "total loss: tensor(4.1094, device='cuda:3', dtype=torch.float16, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/openai/CLIP/issues/57\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "import clip\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "EPOCH =10\n",
    "BATCH_SIZE =256\n",
    "\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "\n",
    "class cocodtrain(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_path='/home/jason/data/coco/images', text_path='/home/jason/data/coco/text', mode='train2014'):\n",
    "\n",
    "        self.image_list = []\n",
    "        self.image_list.extend(glob.glob(os.path.join(image_path, mode, '*.jpg')))\n",
    "        self.image_list.sort()\n",
    "\n",
    "        self.label_list = []\n",
    "        self.label_list.extend(glob.glob(os.path.join(text_path, mode, '*.txt')))\n",
    "        self.label_list.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_list[index]).convert(\"RGB\")\n",
    "        image = image.resize((224,224), Image.BILINEAR)\n",
    "        image = preprocess(image)\n",
    "        #image = np.asarray(image)\n",
    "\n",
    "        with open(self.label_list[index], \"r\") as f:\n",
    "            data = f.readlines()\n",
    "            label = random.choice(data)\n",
    "            \n",
    "        return image, label\n",
    "trainset = cocodtrain('/home/jason/data/coco/images','/home/jason/data/coco/text','train2014')\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "                    trainset, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True, \n",
    "                    num_workers=16,\n",
    "                    drop_last=True)\n",
    "\n",
    "def convert_models_to_fp32(model): \n",
    "    for p in model.parameters(): \n",
    "        p.data = p.data.float() \n",
    "        p.grad.data = p.grad.data.float() \n",
    "\n",
    "#device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
    "#model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "\n",
    "#clip.model.convert_weights(model) # Actually this line is unnecessary since clip by default already on float16\n",
    "\n",
    "loss_img = nn.CrossEntropyLoss()\n",
    "loss_txt = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5,betas=(0.9,0.98),eps=1e-6,weight_decay=0.2) #Params used from paper, the lr is smaller, more safe for fine tuning to new dataset\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print('epoch:', epoch)\n",
    "    for batch in tqdm(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        list_image,list_txt = batch #list_images is list of image in numpy array(np.uint8), or list of PIL images\n",
    "        # print(list_image.size()) #torch.Size([32, 3, 224, 224])\n",
    "      \n",
    "        images = torch.tensor(np.stack(list_image)).to(device)\n",
    "        texts = clip.tokenize(list_txt).to(device) #torch.Size([32, 77])\n",
    "         # print(texts.size()) #torch.Size([32, 77])\n",
    "        logits_per_image, logits_per_text = model(images, texts)\n",
    "        ground_truth = torch.arange(BATCH_SIZE,dtype=torch.long,device=device)\n",
    "\n",
    "        total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
    "        total_loss.backward()\n",
    "        print('total loss:', total_loss)\n",
    "      \n",
    "        convert_models_to_fp32(model)\n",
    "        optimizer.step()\n",
    "        clip.model.convert_weights(model)\n",
    "    \n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': total_loss,\n",
    "    }, f\"model_checkpoint/model_10.pt\") #just change to your preferred folder/filename      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "checkpoint = torch.load(\"model_checkpoint/model_10.pt\")\n",
    "#print(model.input_resolution)\n",
    "# Use these 3 lines if you use default model setting(not training setting) of the clip. For example, if you set context_length to 100 since your string is very long during training, then assign 100 to checkpoint['model_state_dict'][\"context_length\"] \n",
    "# checkpoint['model_state_dict'][\"input_resolution\"] = model.input_resolution #default is 224\n",
    "# checkpoint['model_state_dict'][\"context_length\"] = model.context_length # default is 77\n",
    "# checkpoint['model_state_dict'][\"vocab_size\"] = model.vocab_size \n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip.model import Gauss_model\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model_g = Gauss_model().to(device)\n",
    "\n",
    "trainset = cocodtrain('/home/jason/data/coco/images','/home/jason/data/coco/text','train2014')\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "                    trainset, \n",
    "                    batch_size=32,\n",
    "                    shuffle=True, \n",
    "                    num_workers=0,\n",
    "                    drop_last=True)\n",
    "\n",
    "for epoch in range(1): \n",
    "        for i, (image, text) in enumerate(tqdm(trainloader)):\n",
    "                print(i)\n",
    "                print(image.size())\n",
    "                print(text.size())\n",
    "                #image_features,text_features = model_g(image,text)\n",
    "                \n",
    "      "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c73bc775c6f94d98a067ce096eff928d580e9c541aafc395dafbb8814a34bdf4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('torch171': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
