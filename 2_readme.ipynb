{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaefa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "image = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    # similarity = torch.nn.CosineSimilarity(image_feature1, image_feature2)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    print(logits_per_image)\n",
    "    print(logits_per_text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64fc627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([100, 512])\n",
      "\n",
      "Top predictions:\n",
      "\n",
      "           snake: 65.28%\n",
      "          turtle: 12.26%\n",
      "    sweet_pepper: 3.86%\n",
      "          lizard: 1.88%\n",
      "       crocodile: 1.77%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Download the dataset\n",
    "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n",
    "\n",
    "# Prepare the inputs\n",
    "image, class_id = cifar100[3637]\n",
    "# image2=np.array(image)\n",
    "# #print(image2)\n",
    "# #img = cv2.imread(image2)\n",
    "# cv2.imshow('image', image2)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "print(image_input.shape)\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "\n",
    "# Calculate features\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input)\n",
    "    print(image_features.shape)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "    print(text_features.shape)\n",
    "# Pick the top 5 most similar labels for the image\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "values, indices = similarity[0].topk(5)\n",
    "\n",
    "# Print the result\n",
    "print(\"\\nTop predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be67db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:35<00:00,  5.25it/s]\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.21it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        51300     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.30259D+05    |proj g|=  7.65441D+02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  3.39192D+04    |proj g|=  4.96241D+02\n",
      "\n",
      "At iterate  100    f=  2.93372D+04    |proj g|=  1.13858D+03\n",
      "\n",
      "At iterate  150    f=  2.83932D+04    |proj g|=  4.18957D+02\n",
      "\n",
      "At iterate  200    f=  2.81805D+04    |proj g|=  8.47547D+01\n",
      "\n",
      "At iterate  250    f=  2.81458D+04    |proj g|=  3.42762D+01\n",
      "\n",
      "At iterate  300    f=  2.81389D+04    |proj g|=  9.36279D+00\n",
      "\n",
      "At iterate  350    f=  2.81364D+04    |proj g|=  5.97040D+00\n",
      "\n",
      "At iterate  400    f=  2.81340D+04    |proj g|=  8.25179D+00\n",
      "\n",
      "At iterate  450    f=  2.81285D+04    |proj g|=  1.90362D+01\n",
      "\n",
      "At iterate  500    f=  2.81166D+04    |proj g|=  3.14495D+01\n",
      "\n",
      "At iterate  550    f=  2.81056D+04    |proj g|=  3.57362D+00\n",
      "\n",
      "At iterate  600    f=  2.81027D+04    |proj g|=  2.75133D+00\n",
      "\n",
      "At iterate  650    f=  2.81021D+04    |proj g|=  3.02651D+00\n",
      "\n",
      "At iterate  700    f=  2.81019D+04    |proj g|=  1.34445D+00\n",
      "\n",
      "At iterate  750    f=  2.81018D+04    |proj g|=  9.81402D-01\n",
      "\n",
      "At iterate  800    f=  2.81016D+04    |proj g|=  3.48979D+00\n",
      "\n",
      "At iterate  850    f=  2.81011D+04    |proj g|=  6.67581D+00\n",
      "\n",
      "At iterate  900    f=  2.81004D+04    |proj g|=  4.59549D+00\n",
      "\n",
      "At iterate  950    f=  2.81001D+04    |proj g|=  4.20476D+00\n",
      "\n",
      "At iterate 1000    f=  2.81000D+04    |proj g|=  7.23562D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "51300   1000   1023      1     0     0   7.236D-01   2.810D+04\n",
      "  F =   28100.019670153331     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "Accuracy = 80.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/miniconda3/envs/torch171/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.0min finished\n",
      "/tmp/ipykernel_3930340/1496234255.py:44: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Load the dataset\n",
    "root = os.path.expanduser(\"~/.cache\")\n",
    "train = CIFAR100(root, download=True, train=True, transform=preprocess)\n",
    "test = CIFAR100(root, download=True, train=False, transform=preprocess)\n",
    "\n",
    "\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(dataset, batch_size=100)):\n",
    "            features = model.encode_image(images.to(device))\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "# Calculate the image features\n",
    "train_features, train_labels = get_features(train)\n",
    "test_features, test_labels = get_features(test)\n",
    "\n",
    "# Perform logistic regression\n",
    "classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "print(f\"Accuracy = {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823a1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c73bc775c6f94d98a067ce096eff928d580e9c541aafc395dafbb8814a34bdf4"
  },
  "kernelspec": {
   "display_name": "torch171",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
