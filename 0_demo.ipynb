{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([3, 77])\n",
      "torch.Size([1, 512])\n",
      "torch.Size([3, 512])\n",
      "similarity: [[31.61]\n",
      " [23.81]\n",
      " [22.66]]\n",
      "similarity2: [[31.61 23.81 22.66]]\n",
      "similarity3: tensor([0.2556, 0.2008, 0.1974], device='cuda:3', dtype=torch.float16)\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 1])\n",
      "Label probs: [[0.9927   0.00432  0.003061]]\n"
     ]
    }
   ],
   "source": [
    "#demo\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "image = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).to(device)\n",
    "print(image.size()) #(1,3,224,224)\n",
    "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
    "print(text.size()) #(3,77)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image) #(1,512)\n",
    "    print(image_features.size())\n",
    "    text_features = model.encode_text(text) #(3,512)\n",
    "    print(text_features.size())\n",
    "\n",
    "    similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T\n",
    "    similarity2 = image_features.cpu().numpy() @ text_features.cpu().numpy().T\n",
    "    similarity3 = torch.cosine_similarity(text_features, image_features)\n",
    "\n",
    "    print('similarity:',similarity)\n",
    "    print('similarity2:',similarity2)\n",
    "    print('similarity3:',similarity3)\n",
    "\n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    print(logits_per_image.size()) #(1,3)\n",
    "    print(logits_per_text.size())  #(3,1)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "\n",
      "Top predictions:\n",
      "\n",
      "           tiger: 81.04%\n",
      "         raccoon: 4.79%\n",
      "          rabbit: 1.97%\n",
      "        kangaroo: 1.96%\n",
      "          beaver: 1.37%\n"
     ]
    }
   ],
   "source": [
    "#Zero-Shot Prediction\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "import joblib\n",
    "from clip.model import Gauss_model\n",
    "\n",
    "#from clip.model import CLIP\n",
    "from torch import nn\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "model_g = Gauss_model().to(device)\n",
    "#model_g = model_g.half()\n",
    "#print(model_g)\n",
    "\n",
    "# Download the dataset\n",
    "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n",
    "#print(len(cifar100)) #1000\n",
    "\n",
    "# Prepare the inputs\n",
    "image, class_id = cifar100[3637]\n",
    "#print(class_id) #78\n",
    "image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "#print(cifar100.classes[class_id]) #snake\n",
    "\n",
    "# Calculate features\n",
    "with torch.no_grad():\n",
    "    # image_features = model.encode_image(image_input)\n",
    "    # text_features = model.encode_text(text_inputs)\n",
    "    image_features,text_features = model_g(image_input,text_inputs)\n",
    "    #image_features,text_features=model_g(image_features,text_features)\n",
    "\n",
    "# Pick the top 5 most similar labels for the image\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "#print(image_features.size()) #torch.Size([1, 512])\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "#print(text_features.size()) #torch.Size([100, 512])\n",
    "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "values, indices = similarity[0].topk(5)\n",
    "#print('values:',similarity[0].size()) # torch.Size([100])\n",
    "\n",
    "#Print the result\n",
    "print(\"\\nTop predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:53<00:00,  1.08s/it]\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'joblib_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jason/CLIP/0_demo.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224135303030227d/home/jason/CLIP/0_demo.ipynb#ch0000002vscode-remote?line=62'>63</a>\u001b[0m joblib_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjoblib_model.pkl\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224135303030227d/home/jason/CLIP/0_demo.ipynb#ch0000002vscode-remote?line=63'>64</a>\u001b[0m \u001b[39m#model = classifier\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224135303030227d/home/jason/CLIP/0_demo.ipynb#ch0000002vscode-remote?line=64'>65</a>\u001b[0m \u001b[39m#joblib.dump(model, joblib_file)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224135303030227d/home/jason/CLIP/0_demo.ipynb#ch0000002vscode-remote?line=65'>66</a>\u001b[0m \u001b[39m# Load from file\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224135303030227d/home/jason/CLIP/0_demo.ipynb#ch0000002vscode-remote?line=66'>67</a>\u001b[0m joblib_model \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(joblib_file)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224135303030227d/home/jason/CLIP/0_demo.ipynb#ch0000002vscode-remote?line=67'>68</a>\u001b[0m \u001b[39m# # Calculate the accuracy and predictions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224135303030227d/home/jason/CLIP/0_demo.ipynb#ch0000002vscode-remote?line=68'>69</a>\u001b[0m \u001b[39m# score = joblib_model.score(Xtest, Ytest)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224135303030227d/home/jason/CLIP/0_demo.ipynb#ch0000002vscode-remote?line=69'>70</a>\u001b[0m \u001b[39m# print(\"Test score: {0:.2f} %\".format(100 * score))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224135303030227d/home/jason/CLIP/0_demo.ipynb#ch0000002vscode-remote?line=70'>71</a>\u001b[0m \u001b[39m# Ypredict = pickle_model.predict(Xtest)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224135303030227d/home/jason/CLIP/0_demo.ipynb#ch0000002vscode-remote?line=72'>73</a>\u001b[0m \u001b[39mprint\u001b[39m(joblib_model)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch171/lib/python3.8/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jason/miniconda3/envs/torch171/lib/python3.8/site-packages/joblib/numpy_pickle.py?line=574'>575</a>\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    <a href='file:///home/jason/miniconda3/envs/torch171/lib/python3.8/site-packages/joblib/numpy_pickle.py?line=575'>576</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/jason/miniconda3/envs/torch171/lib/python3.8/site-packages/joblib/numpy_pickle.py?line=576'>577</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    <a href='file:///home/jason/miniconda3/envs/torch171/lib/python3.8/site-packages/joblib/numpy_pickle.py?line=577'>578</a>\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[1;32m    <a href='file:///home/jason/miniconda3/envs/torch171/lib/python3.8/site-packages/joblib/numpy_pickle.py?line=578'>579</a>\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    <a href='file:///home/jason/miniconda3/envs/torch171/lib/python3.8/site-packages/joblib/numpy_pickle.py?line=579'>580</a>\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jason/miniconda3/envs/torch171/lib/python3.8/site-packages/joblib/numpy_pickle.py?line=580'>581</a>\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jason/miniconda3/envs/torch171/lib/python3.8/site-packages/joblib/numpy_pickle.py?line=581'>582</a>\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'joblib_model.pkl'"
     ]
    }
   ],
   "source": [
    "#zero-shot evaluation\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Load the dataset\n",
    "root = os.path.expanduser(\"~/.cache\")\n",
    "train = CIFAR100(root, download=True, train=True, transform=preprocess)\n",
    "test = CIFAR100(root, download=True, train=False, transform=preprocess)\n",
    "#print(cifar100.classes)\n",
    "\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(dataset, batch_size=1000)):\n",
    "            features = model.encode_image(images.to(device))\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "# Calculate the image features\n",
    "train_features, train_labels = get_features(train)\n",
    "test_features, test_labels = get_features(test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Perform logistic regression\n",
    "#classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\n",
    "#classifier.fit(train_features, train_labels)\n",
    "\n",
    "# # Pick the top 5 most similar labels for the image\n",
    "# image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "# text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "# similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "# values, indices = similarity[0].topk(5)\n",
    "\n",
    "# # Print the result\n",
    "# print(\"\\nTop predictions:\\n\")\n",
    "# for value, index in zip(values, indices):\n",
    "#     print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")\n",
    "\n",
    "#from sklearn.externals import joblib\n",
    "#import sklearn.external.joblib as extjoblib\n",
    "# Save to file in the current working directory\n",
    "joblib_file = \"joblib_model.pkl\"\n",
    "#model = classifier\n",
    "#joblib.dump(model, joblib_file)\n",
    "# Load from file\n",
    "joblib_model = joblib.load(joblib_file)\n",
    "# # Calculate the accuracy and predictions\n",
    "# score = joblib_model.score(Xtest, Ytest)\n",
    "# print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "# Ypredict = pickle_model.predict(Xtest)\n",
    "\n",
    "print(joblib_model)\n",
    "classifier= joblib_model\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features) # test_features (10000,512)\n",
    "print('predictions:',len(predictions)) #(10000,)\n",
    "print('test_label:',len(test_labels)) #(10000,)\n",
    "\n",
    "accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "print(f\"Accuracy = {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:53<00:00,  9.32it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  9.04it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        51300     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.30259D+05    |proj g|=  7.65441D+02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  3.39192D+04    |proj g|=  4.96241D+02\n",
      "\n",
      "At iterate  100    f=  2.93372D+04    |proj g|=  1.13858D+03\n",
      "\n",
      "At iterate  150    f=  2.83932D+04    |proj g|=  4.18957D+02\n",
      "\n",
      "At iterate  200    f=  2.81805D+04    |proj g|=  8.47547D+01\n",
      "\n",
      "At iterate  250    f=  2.81458D+04    |proj g|=  3.42762D+01\n",
      "\n",
      "At iterate  300    f=  2.81389D+04    |proj g|=  9.36279D+00\n",
      "\n",
      "At iterate  350    f=  2.81364D+04    |proj g|=  5.97040D+00\n",
      "\n",
      "At iterate  400    f=  2.81340D+04    |proj g|=  8.25179D+00\n",
      "\n",
      "At iterate  450    f=  2.81285D+04    |proj g|=  1.90362D+01\n",
      "\n",
      "At iterate  500    f=  2.81166D+04    |proj g|=  3.14495D+01\n",
      "\n",
      "At iterate  550    f=  2.81056D+04    |proj g|=  3.57362D+00\n",
      "\n",
      "At iterate  600    f=  2.81027D+04    |proj g|=  2.75133D+00\n",
      "\n",
      "At iterate  650    f=  2.81021D+04    |proj g|=  3.02651D+00\n",
      "\n",
      "At iterate  700    f=  2.81019D+04    |proj g|=  1.34445D+00\n",
      "\n",
      "At iterate  750    f=  2.81018D+04    |proj g|=  9.81402D-01\n",
      "\n",
      "At iterate  800    f=  2.81016D+04    |proj g|=  3.48979D+00\n",
      "\n",
      "At iterate  850    f=  2.81011D+04    |proj g|=  6.67581D+00\n",
      "\n",
      "At iterate  900    f=  2.81004D+04    |proj g|=  4.59549D+00\n",
      "\n",
      "At iterate  950    f=  2.81001D+04    |proj g|=  4.20476D+00\n",
      "\n",
      "At iterate 1000    f=  2.81000D+04    |proj g|=  7.23562D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "51300   1000   1023      1     0     0   7.236D-01   2.810D+04\n",
      "  F =   28100.019670153331     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "Accuracy = 80.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/miniconda3/envs/torch171/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.7min finished\n",
      "/tmp/ipykernel_193307/2905345801.py:45: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n"
     ]
    }
   ],
   "source": [
    "#Linear-probe evaluation\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Load the dataset\n",
    "root = os.path.expanduser(\"~/.cache\")\n",
    "train = CIFAR100(root, download=True, train=True, transform=preprocess)\n",
    "test = CIFAR100(root, download=True, train=False, transform=preprocess)\n",
    "\n",
    "\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(dataset, batch_size=100)):\n",
    "            features = model.encode_image(images.to(device))\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "# Calculate the image features\n",
    "train_features, train_labels = get_features(train)\n",
    "test_features, test_labels = get_features(test)\n",
    "\n",
    "# Perform logistic regression\n",
    "classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "print(f\"Accuracy = {accuracy:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c73bc775c6f94d98a067ce096eff928d580e9c541aafc395dafbb8814a34bdf4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('torch171': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
